{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomik062/AI_Project/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extract data from github and merge together"
      ],
      "metadata": {
        "id": "QoOciPbUXoL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import importlib.util\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV, LeaveOneOut,KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Lasso,ElasticNet\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "# Define the GitHub details\n",
        "def init_process():\n",
        "  repo_owner = 'tomik062'\n",
        "  repo_name = 'AI_Project'\n",
        "  file_path = 'extract_data.py'\n",
        "  url = f'https://raw.githubusercontent.com/{repo_owner}/{repo_name}/main/{file_path}'\n",
        "\n",
        "  # Directory to save the downloaded file\n",
        "  download_dir = 'data_extraction_code'\n",
        "  if not os.path.exists(download_dir):\n",
        "      os.makedirs(download_dir)\n",
        "\n",
        "  local_file_path = os.path.join(download_dir, file_path)\n",
        "\n",
        "  # Download the file\n",
        "  response = requests.get(url)\n",
        "  response.raise_for_status() # Raise an exception for bad status codes\n",
        "\n",
        "  with open(local_file_path, 'wb') as f:\n",
        "      f.write(response.content)\n",
        "\n",
        "  print(f\"Downloaded {file_path} to {local_file_path}\")\n",
        "\n",
        "  # Import the function from the downloaded file\n",
        "  spec = importlib.util.spec_from_file_location(\"extract_data_module\", local_file_path)\n",
        "  module = importlib.util.module_from_spec(spec)\n",
        "  spec.loader.exec_module(module)\n",
        "  # Call the extract_data function and print the output\n",
        "  return module.extract_data()"
      ],
      "metadata": {
        "id": "prjUcK7VXGll"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_features_year(data,year):\n",
        "    feature_map = {\n",
        "        'urbanization': 0,\n",
        "        'avg birth age': 1,\n",
        "        'happiness': 2,\n",
        "        'health expenditure': 3,\n",
        "        'physicians per capita': 4,\n",
        "        'GNI PPP': 5,\n",
        "        'female labor participation': 6,\n",
        "        'christians': 7,\n",
        "        'muslims': 8,\n",
        "        'no religion': 9,\n",
        "        'buddhists': 10,\n",
        "        'hindus': 11,\n",
        "        'jews': 12,\n",
        "        'other religion': 13,\n",
        "        'in Asia-Pacific':14,\n",
        "        'in Europe':15,\n",
        "        'in Latin America-Caribbean':16,\n",
        "        'in Middle East-North Africa':17,\n",
        "        'in North America':18,\n",
        "        'in Sub-Saharan Africa':19,\n",
        "        'education man': 20,\n",
        "        'education women': 21,\n",
        "        'hdi': 22,\n",
        "        'gii': 23,\n",
        "        'avg marriage age women': 24,\n",
        "        'avg marriage age men': 25,\n",
        "        'maternity leave index': 26,\n",
        "        'work hours men': 27,\n",
        "        'work hours women': 28,\n",
        "        'abortions': 29,\n",
        "        'social media users': 30\n",
        "    }\n",
        "    countries = sorted(list(set([key[0] for key in data.keys()])))\n",
        "    df = pd.DataFrame(index=countries, columns=feature_map.keys())\n",
        "    target=[]\n",
        "    # Populate the DataFrame\n",
        "    for country in countries:\n",
        "        key = (country, year)\n",
        "        if key in data:\n",
        "            features = data[key][1]\n",
        "            target.append(data[key][0])\n",
        "            for feature_name, feature_index in feature_map.items():\n",
        "                if feature_index < len(features):\n",
        "                  df.loc[country, feature_name] = features[feature_index]\n",
        "                  if str(features[feature_index]) =='nan':\n",
        "                    df.loc[country, feature_name]=handle_missing_values(data,feature_index,country,year)\n",
        "    return df,target\n",
        "\n",
        "\n",
        "\n",
        "def handle_missing_values(data, feature_index, country, year):\n",
        "    # try taking the value from the last 3 years\n",
        "    for i in range(1, 4):\n",
        "        past_year = year - i\n",
        "        if (country, past_year) in data:\n",
        "            past_data = data[(country, past_year)][1] # Access the list of features\n",
        "            if feature_index < len(past_data) and str(past_data[feature_index])!='nan':\n",
        "                return past_data[feature_index]\n",
        "\n",
        "    # otherwise if missing last 3 years, linearly extrapulate from last decade\n",
        "    recent_years_data = []\n",
        "    for i in range(10,0,-1):\n",
        "        past_year = year - i\n",
        "        if (country, past_year) in data:\n",
        "            past_data = data[(country, past_year)][1] # Access the list of features\n",
        "            if feature_index < len(past_data) and not pd.isna(past_data[feature_index]):\n",
        "                 recent_years_data.append((past_year, past_data[feature_index]))\n",
        "\n",
        "    if len(recent_years_data) >= 2:\n",
        "        years = [item[0] for item in recent_years_data]\n",
        "        values = [item[1] for item in recent_years_data]\n",
        "        # Linear extrapolation using linear regression with polyfit\n",
        "        try:\n",
        "            m, c = np.polyfit(years, values, 1)\n",
        "            extrapolated_value = m * year + c\n",
        "            return extrapolated_value\n",
        "        except np.linalg.LinAlgError:\n",
        "            # Handle cases where polyfit fails (e.g., all years are the same)\n",
        "            return values[-1] # Return the last known value\n",
        "    elif len(recent_years_data) == 1:\n",
        "         # If only one data point in the last 10 years, use that value\n",
        "         return recent_years_data[0][1]\n",
        "\n",
        "    # If still missing after checking last 10 years, return NaN\n",
        "    return np.nan"
      ],
      "metadata": {
        "id": "cCWbIjgpEHDt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_missing_features(df_features):\n",
        "\n",
        "  # Identify countries with and without NaN values\n",
        "  countries_with_nan = df_features[df_features.isnull().any(axis=1)].index.tolist()\n",
        "  countries_without_nan = df_features.dropna().index.tolist()\n",
        "  countries_with_one_nan = df_features[df_features.isnull().sum(axis=1) == 1].index.tolist()\n",
        "\n",
        "  # Print the results\n",
        "  print(\"Countries with NaN values in their features:\")\n",
        "  print(countries_with_nan)\n",
        "  print(\"\\nCountries without NaN values in their features:\")\n",
        "  print(countries_without_nan)\n",
        "  print(\"\\nCountries with exactly one NaN value in their features:\")\n",
        "  print(countries_with_one_nan)\n",
        "\n",
        "  print(f\"\\nNumber of countries with NaN values: {len(countries_with_nan)}\")\n",
        "  print(f\"Number of countries without NaN values: {len(countries_without_nan)}\")\n",
        "  print(f\"Number of countries with exactly one NaN value: {len(countries_with_one_nan)}\")\n",
        "\n",
        "  # Group countries by their single missing feature\n",
        "  missing_features_grouped = {}\n",
        "  if countries_with_one_nan:\n",
        "      for country in countries_with_one_nan:\n",
        "          missing_feature_name = df_features.loc[country].isnull().idxmax()\n",
        "          if missing_feature_name not in missing_features_grouped:\n",
        "              missing_features_grouped[missing_feature_name] = []\n",
        "          missing_features_grouped[missing_feature_name].append(country)\n",
        "\n",
        "      # Print countries grouped by missing feature\n",
        "      print(\"\\nMissing feature for countries with exactly one NaN:\")\n",
        "      for feature, countries in missing_features_grouped.items():\n",
        "          print(f\"  Missing feature is '{feature}':\")\n",
        "          print(f\"    Countries: {', '.join(countries)}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4H0S2X3MyK0n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "process 2023 data:\n",
        "add some missing data, split to train and test and normalize"
      ],
      "metadata": {
        "id": "AHHje3EPAzwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_2023_data(data_output):\n",
        "    df_features, target = calc_features_year(data_output, 2023)\n",
        "    missing_values_to_fill = {\n",
        "        'abortions': {\n",
        "            'Cyprus': 7,'Ireland': 6.7,'Malaysia': 11,\n",
        "            'Mauritania': 42,'Malta': 3,'Morocco': 25, 'Congo, Rep.': 39\n",
        "        },\n",
        "        'maternity leave index': {\n",
        "            'Albania': 23.23,'Bosnia and Herzegovina': 52.14,\n",
        "            'Kazakhstan': 18,'Georgia': 7.59,'Kyrgyz Republic': 18,\n",
        "            'Moldova': 18,'Angola': 13,'Armenia': 20,\n",
        "            'Azerbaijan': 18,'Malawi': 12.86,'Bhutan': 8,\n",
        "            'Tanzania': 12,'Tajikistan': 20,'North Macedonia': 39,\n",
        "            'Liberia': 12.86,'Suriname': 0,'Uzbekistan': 18\n",
        "        },\n",
        "        'gii':{\n",
        "            'Central African Republic':0.682\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Fill in missing values using the dictionary\n",
        "    for feature, country_values in missing_values_to_fill.items():\n",
        "        for country, value in country_values.items():\n",
        "            if country in df_features.index:\n",
        "                df_features.loc[country, feature] = value\n",
        "\n",
        "\n",
        "    # Create a DataFrame for the target variable\n",
        "    y = pd.Series(target, index=df_features.index, name='target')\n",
        "\n",
        "    # Combine features and target into a single DataFrame for easier NaN handling\n",
        "    combined_df = pd.concat([df_features, y], axis=1)\n",
        "\n",
        "    # Remove rows with NaN values\n",
        "    combined_df_cleaned = combined_df.dropna()\n",
        "\n",
        "    # Separate features and target again\n",
        "    X = combined_df_cleaned.drop('target', axis=1)\n",
        "    y = combined_df_cleaned['target']\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "o11f5CwCA_bK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_features(X_train):\n",
        "\n",
        "  # Get the list of columns\n",
        "  columns = X_train.columns\n",
        "\n",
        "  # Calculate the number of rows needed\n",
        "  n_cols = 6\n",
        "  n_rows = math.ceil(len(columns) / n_cols)\n",
        "\n",
        "  # Create subplots\n",
        "  fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5))\n",
        "  axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
        "\n",
        "  # Plot histograms for all features\n",
        "  for i, column in enumerate(columns):\n",
        "      axes[i].hist(X_train[column], bins=10)\n",
        "      axes[i].set_title(f'Histogram of {column}')\n",
        "      axes[i].set_xlabel(column)\n",
        "      axes[i].set_ylabel('Frequency')\n",
        "      axes[i].grid(True)\n",
        "\n",
        "  # Hide any unused subplots\n",
        "  for j in range(i + 1, len(axes)):\n",
        "      fig.delaxes(axes[j])\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-3EC63LtmKt7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaling_2023(X_train, X_test):\n",
        "    # Create copies to avoid modifying the original DataFrames\n",
        "    X_train = X_train.copy()\n",
        "    X_test = X_test.copy()\n",
        "\n",
        "    log_features = ['no religion', 'other religion', 'buddhists', 'hindus', 'jews','GNI PPP']\n",
        "    for feature in log_features:\n",
        "        X_train[feature] = pd.to_numeric(X_train[feature])\n",
        "        X_test[feature] = pd.to_numeric(X_test[feature])\n",
        "        # Apply log1p transformation\n",
        "        X_train[feature] = np.log1p(X_train[feature])\n",
        "        X_test[feature] = np.log1p(X_test[feature])\n",
        "\n",
        "    # Standard scale all features except region features\n",
        "    features_to_scale = [\n",
        "        'urbanization', 'avg birth age', 'happiness', 'GNI PPP',\n",
        "        'female labor participation', 'christians', 'muslims', 'no religion',\n",
        "        'buddhists', 'hindus', 'jews', 'other religion', 'education man',\n",
        "        'education women', 'hdi', 'gii', 'avg marriage age women',\n",
        "        'avg marriage age men', 'maternity leave index', 'work hours men',\n",
        "        'work hours women', 'abortions', 'social media users',\n",
        "        'physicians per capita', 'health expenditure'\n",
        "    ]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "    X_test[features_to_scale] = scaler.transform(X_test[features_to_scale])\n",
        "\n",
        "    # Create 'healthcare index score'\n",
        "    X_train['healthcare index score'] = X_train['physicians per capita'] + X_train['health expenditure']\n",
        "    X_test['healthcare index score'] = X_test['physicians per capita'] + X_test['health expenditure']\n",
        "    scaler_healthcare = StandardScaler()\n",
        "    X_train['healthcare index score'] = scaler_healthcare.fit_transform(X_train[['healthcare index score']])\n",
        "    X_test['healthcare index score'] = scaler_healthcare.transform(X_test[['healthcare index score']])\n",
        "\n",
        "    # Remove original 'physicians per capita' and 'health expenditure' features\n",
        "    X_train = X_train.drop(['physicians per capita', 'health expenditure'], axis=1)\n",
        "    X_test = X_test.drop(['physicians per capita', 'health expenditure'], axis=1)\n",
        "\n",
        "    return X_train, X_test"
      ],
      "metadata": {
        "id": "RjJlouYJ5XTb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_correlations(df, method):\n",
        "    \"\"\"Calculates and visualizes correlation matrix, and prints top 5 correlated pairs.\"\"\"\n",
        "\n",
        "    correlation_matrix = df.corr(method=method)\n",
        "\n",
        "    plt.figure(figsize=(18, 15))\n",
        "    sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title(f'{method.capitalize()} Correlation Heatmap of Features in X_train')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nTop 5 most highly correlated pairs of features (absolute {method.capitalize()} correlation):\")\n",
        "    upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
        "    stacked_corr = upper_tri.stack().sort_values(ascending=False, key=abs)\n",
        "    top_5_correlated_pairs = stacked_corr.head(5)\n",
        "\n",
        "    if top_5_correlated_pairs.empty:\n",
        "        print(\"No correlated pairs found.\")\n",
        "    else:\n",
        "        for (feature1, feature2), correlation in top_5_correlated_pairs.items():\n",
        "            print(f\"  {feature1} and {feature2}: {correlation:.4f}\")\n"
      ],
      "metadata": {
        "id": "hOqocTAfnYe2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_target_correlation(X, y, method_name):\n",
        "    combined_data = pd.concat([X, y], axis=1)\n",
        "    correlation_series = combined_data.corr(method=method_name)['target'].drop('target').sort_values(ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x=correlation_series.values, y=correlation_series.index, palette='coolwarm')\n",
        "    plt.title(f'{method_name} Correlation of Features with Target Variable')\n",
        "    plt.xlabel(f'{method_name} Correlation Coefficient')\n",
        "    plt.ylabel('Features')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n{method_name} Correlation with Target:\")\n",
        "    print(correlation_series)\n"
      ],
      "metadata": {
        "id": "rP_0P9DHkpAd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_mutual_information(X, y):\n",
        "    \"\"\"Calculates and displays Mutual Information scores of features with the target.\"\"\"\n",
        "    mi_scores = mutual_info_regression(X, y)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "\n",
        "    print(\"Mutual Information Scores of Features with Target Variable:\")\n",
        "    print(mi_scores)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=mi_scores.values, y=mi_scores.index, palette='viridis')\n",
        "    plt.title('Mutual Information Scores of Features with Target Variable')\n",
        "    plt.xlabel('Mutual Information Score')\n",
        "    plt.ylabel('Features')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iCz9f_EgB21d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "797c2b1f"
      },
      "source": [
        "def gridsearch_loocv_lasso(X, y):\n",
        "    lasso = Lasso()\n",
        "    loo = LeaveOneOut()\n",
        "    param_grid = {'alpha': [val * (10**i) for i in range(-12, 4) for val in [1, 2, 5]]}\n",
        "    grid_search = GridSearchCV(estimator=lasso, param_grid=param_grid,\n",
        "                               cv=loo, scoring='neg_mean_squared_error',\n",
        "                               n_jobs=-1)\n",
        "    grid_search.fit(X, y)\n",
        "    return grid_search\n",
        "\n",
        "def gridsearch_elastic_net_loocv(X, y):\n",
        "    elastic_net = ElasticNet()\n",
        "    loo = LeaveOneOut()\n",
        "    param_grid = {'alpha': [val * (10**i) for i in range(-6, 2) for val in [1, 2, 5]],\n",
        "        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99,0.995, 1.0]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=elastic_net, param_grid=param_grid,\n",
        "                               cv=loo, scoring='neg_mean_squared_error',\n",
        "                               n_jobs=-1)\n",
        "    grid_search.fit(X, y)\n",
        "    return grid_search"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 2023 data##\n",
        "X_train, X_test, y_train, y_test = process_2023_data(init_process())\n",
        "\n",
        "#feature distrebutions\n",
        "print('unscaled features')\n",
        "plot_features(X_train)\n",
        "scaled_train, scaled_test = scaling_2023(X_train, X_test)\n",
        "print('scaled features')\n",
        "plot_features(scaled_train)\n",
        "\n",
        "#feature pairs correlations\n",
        "feature_correlations(scaled_train, 'pearson')\n",
        "feature_correlations(scaled_train, 'spearman')\n",
        "#feature-target correlations and mutual information\n",
        "analyze_target_correlation(scaled_train, y_train, 'pearson')\n",
        "analyze_target_correlation(scaled_train, y_train, 'spearman')\n",
        "analyze_mutual_information(scaled_train, y_train)\n",
        "\n",
        "#lasso regressor model\n",
        "grid_search_result = gridsearch_loocv_lasso(scaled_train, y_train)\n",
        "print(\"Best parameters found: \", grid_search_result.best_params_)\n",
        "print(\"Best cross-validation score (negative MSE): \", grid_search_result.best_score_)\n",
        "best_lasso_model = grid_search_result.best_estimator_\n",
        "print(\"Coefficients of the best Lasso model:\")\n",
        "for feature, coef in zip(scaled_train.columns, best_lasso_model.coef_):\n",
        "    print(f\"{feature}: {coef:.4f}\")\n",
        "\n",
        "#elastic net regressor model\n",
        "elastic_net_grid_search_result = gridsearch_elastic_net_loocv(scaled_train, y_train)\n",
        "print(\"Best parameters found for Elastic Net (LOOCV): \", elastic_net_grid_search_result.best_params_)\n",
        "print(\"Best cross-validation score (negative MSE) for Elastic Net (LOOCV): \", elastic_net_grid_search_result.best_score_)\n",
        "best_elastic_net_model = elastic_net_grid_search_result.best_estimator_\n",
        "print(\"\\nCoefficients of the best Elastic Net model (LOOCV):\")\n",
        "for feature, coef in zip(scaled_train.columns, best_elastic_net_model.coef_):\n",
        "    print(f\"{feature}: {coef:.4f}\")\n",
        "\n",
        "#random forest regressor model\n",
        "RF_grid_search_result = gridsearch_random_forest(scaled_train, y_train)\n",
        "print(\"Best parameters found for Random Forest: (5 fold cv)\", grid_search_result.best_params_)\n",
        "print(\"Best cross-validation score (negative MSE) for Rnadom Forest: \", grid_search_result.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "8lHd4iGFxsFn",
        "outputId": "15293723-17aa-40dc-a607-2e84749a7992"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded extract_data.py to data_extraction_code/extract_data.py\n",
            "Downloaded GNI_PPP_const_2021_dollars.csv to data/GNI_PPP_const_2021_dollars.csv\n",
            "Downloaded Religious-Composition-percentages.csv to data/Religious-Composition-percentages.csv\n",
            "Downloaded abortion-rates-by-country-2025.csv to data/abortion-rates-by-country-2025.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-3486595863.py\", line 2, in <cell line: 0>\n",
            "    X_train, X_test, y_train, y_test = process_2023_data(init_process())\n",
            "                                                         ^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1838688634.py\", line 42, in init_process\n",
            "    spec.loader.exec_module(module)\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/content/data_extraction_code/extract_data.py\", line 33, in <module>\n",
            "    file_content = requests.get(download_url).content\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/api.py\", line 73, in get\n",
            "    return request(\"get\", url, params=params, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/api.py\", line 59, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/adapters.py\", line 667, in send\n",
            "    resp = conn.urlopen(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
            "    response = self._make_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\", line 534, in _make_request\n",
            "    response = conn.getresponse()\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\", line 565, in getresponse\n",
            "    httplib_response = super().getresponse()\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 1430, in getresponse\n",
            "    response.begin()\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 331, in begin\n",
            "    version, status, reason = self._read_status()\n",
            "                              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 292, in _read_status\n",
            "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/socket.py\", line 720, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ssl.py\", line 1251, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ssl.py\", line 1103, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1718, in getframeinfo\n",
            "    lines, lnum = findsource(frame)\n",
            "                  ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 170, in findsource\n",
            "    file = getsourcefile(object) or getfile(object)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 970, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1007, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3486595863.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## 2023 data##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_2023_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1838688634.py\u001b[0m in \u001b[0;36minit_process\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m   \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m   \u001b[0;31m# Call the extract_data function and print the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/content/data_extraction_code/extract_data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdownload_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'download_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b35a7c0c"
      },
      "source": [
        "def gridsearch_random_forest(X, y):\n",
        "  rf_model = RandomForestRegressor(random_state=42)\n",
        "  kf = KFold(n_splits=5,shuffle=True,random_state=42)\n",
        "\n",
        "  param_grid = {\n",
        "      'n_estimators': [25, 50, 100, 200 ,400],\n",
        "      'max_depth': [2,3,4,5,None],\n",
        "      'min_samples_split': [2,3,5,10,20],\n",
        "      'min_samples_leaf': [1,2,3,5,8,15]\n",
        "  }\n",
        "\n",
        "  grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid,\n",
        "                                cv=kf, scoring='neg_mean_squared_error',\n",
        "                                n_jobs=-1)\n",
        "\n",
        "  grid_search_rf.fit(X, y)\n",
        "  return grid_search_rf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_result = gridsearch_random_forest(scaled_train, y_train)\n",
        "print(\"Best parameters found for Random Forest: \", random_forest_result.best_params_)\n",
        "print(\"Best cross-validation score (negative MSE) for Random Forest: \", random_forest_result.best_score_)"
      ],
      "metadata": {
        "id": "kqSbItNtOv_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Assuming grid_search_rf, X_train, y_train, X_test, and y_test are already defined\n",
        "\n",
        "# Get the best trained Random Forest model\n",
        "best_rf_model = random_forest_result.best_estimator_\n",
        "\n",
        "# --- Evaluate on Training Set ---\n",
        "y_train_pred_rf = best_rf_model.predict(scaled_train)\n",
        "mse_train_rf = mean_squared_error(y_train, y_train_pred_rf)\n",
        "r2_train_rf = r2_score(y_train, y_train_pred_rf)\n",
        "\n",
        "print(f\"Training Set Performance:\")\n",
        "print(f\"  Mean Squared Error: {mse_train_rf:.4f}\")\n",
        "print(f\"  R-squared: {r2_train_rf:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# --- Evaluate on Test Set ---\n",
        "y_test_pred_rf = best_rf_model.predict(scaled_test)\n",
        "mse_test_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
        "r2_test_rf = r2_score(y_test, y_test_pred_rf)\n",
        "\n",
        "print(f\"Test Set Performance:\")\n",
        "print(f\"  Mean Squared Error: {mse_test_rf:.4f}\")\n",
        "print(f\"  R-squared: {r2_test_rf:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# --- Validation Set Performance (from Grid Search) ---\n",
        "# The best_score_ from GridSearchCV is the mean cross-validation score (negative MSE)\n",
        "validation_neg_mse = random_forest_result.best_score_\n",
        "validation_mse = -validation_neg_mse # Convert negative MSE to positive MSE\n",
        "\n",
        "print(f\"Validation Set Performance (from Grid Search):\")\n",
        "print(f\"  Mean Cross-Validation MSE: {validation_mse:.4f}\")\n",
        "# Note: R-squared is not directly available from best_score_ if MSE was the scoring metric\n",
        "# You could calculate R-squared on the validation folds separately if needed."
      ],
      "metadata": {
        "id": "M7d6P0I32lOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_G-9gBjwS-X0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
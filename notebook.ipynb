{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomik062/AI_Project/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "install and import all libraries"
      ],
      "metadata": {
        "id": "7jtPR47PYfsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dowhy\n",
        "import requests\n",
        "import os\n",
        "import importlib.util\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import logging\n",
        "import warnings\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV, LeaveOneOut,KFold\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Lasso,ElasticNet, Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from dowhy import CausalModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsLpJ_apYmVs",
        "outputId": "e01b1a0d-e889-4064-dc77-3900c8a886b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dowhy in /usr/local/lib/python3.12/dist-packages (0.13)\n",
            "Requirement already satisfied: causal-learn>=0.1.3.0 in /usr/local/lib/python3.12/dist-packages (from dowhy) (0.1.4.3)\n",
            "Requirement already satisfied: cvxpy<1.5 in /usr/local/lib/python3.12/dist-packages (from dowhy) (1.4.4)\n",
            "Requirement already satisfied: cython>=3.0 in /usr/local/lib/python3.12/dist-packages (from dowhy) (3.0.12)\n",
            "Requirement already satisfied: joblib>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from dowhy) (1.5.2)\n",
            "Requirement already satisfied: networkx>=3.3 in /usr/local/lib/python3.12/dist-packages (from dowhy) (3.5)\n",
            "Requirement already satisfied: numba>=0.59 in /usr/local/lib/python3.12/dist-packages (from dowhy) (0.60.0)\n",
            "Requirement already satisfied: numpy>1.0 in /usr/local/lib/python3.12/dist-packages (from dowhy) (2.0.2)\n",
            "Requirement already satisfied: pandas>1.0 in /usr/local/lib/python3.12/dist-packages (from dowhy) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>1.0 in /usr/local/lib/python3.12/dist-packages (from dowhy) (1.6.1)\n",
            "Requirement already satisfied: scipy<=1.15.3 in /usr/local/lib/python3.12/dist-packages (from dowhy) (1.15.3)\n",
            "Requirement already satisfied: statsmodels>=0.14 in /usr/local/lib/python3.12/dist-packages (from dowhy) (0.14.5)\n",
            "Requirement already satisfied: sympy>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from dowhy) (1.13.3)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from dowhy) (4.67.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from causal-learn>=0.1.3.0->dowhy) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from causal-learn>=0.1.3.0->dowhy) (3.10.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.12/dist-packages (from causal-learn>=0.1.3.0->dowhy) (3.0.4)\n",
            "Requirement already satisfied: momentchi2 in /usr/local/lib/python3.12/dist-packages (from causal-learn>=0.1.3.0->dowhy) (0.1.8)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.12/dist-packages (from cvxpy<1.5->dowhy) (1.0.4)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.12/dist-packages (from cvxpy<1.5->dowhy) (2.0.14)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from cvxpy<1.5->dowhy) (0.11.1)\n",
            "Requirement already satisfied: scs>=3.0 in /usr/local/lib/python3.12/dist-packages (from cvxpy<1.5->dowhy) (3.2.8)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.12/dist-packages (from cvxpy<1.5->dowhy) (3.0.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.59->dowhy) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>1.0->dowhy) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>1.0->dowhy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>1.0->dowhy) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>1.0->dowhy) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.14->dowhy) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.14->dowhy) (25.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.10.1->dowhy) (1.3.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.12/dist-packages (from clarabel>=0.5.0->cvxpy<1.5->dowhy) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from osqp>=0.6.2->cvxpy<1.5->dowhy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from osqp>=0.6.2->cvxpy<1.5->dowhy) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>1.0->dowhy) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (3.2.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi->clarabel>=0.5.0->cvxpy<1.5->dowhy) (2.23)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->osqp>=0.6.2->cvxpy<1.5->dowhy) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extract data from github and merge together"
      ],
      "metadata": {
        "id": "QoOciPbUXoL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the GitHub details\n",
        "def init_process():\n",
        "  repo_owner = 'tomik062'\n",
        "  repo_name = 'AI_Project'\n",
        "  file_path = 'extract_data.py'\n",
        "  url = f'https://raw.githubusercontent.com/{repo_owner}/{repo_name}/main/{file_path}'\n",
        "\n",
        "  # Directory to save the downloaded file\n",
        "  download_dir = 'data_extraction_code'\n",
        "  if not os.path.exists(download_dir):\n",
        "      os.makedirs(download_dir)\n",
        "\n",
        "  local_file_path = os.path.join(download_dir, file_path)\n",
        "\n",
        "  # Download the file\n",
        "  response = requests.get(url)\n",
        "  response.raise_for_status() # Raise an exception for bad status codes\n",
        "\n",
        "  with open(local_file_path, 'wb') as f:\n",
        "      f.write(response.content)\n",
        "\n",
        "  print(f\"Downloaded {file_path} to {local_file_path}\")\n",
        "\n",
        "  # Import the function from the downloaded file\n",
        "  spec = importlib.util.spec_from_file_location(\"extract_data_module\", local_file_path)\n",
        "  module = importlib.util.module_from_spec(spec)\n",
        "  spec.loader.exec_module(module)\n",
        "  # Call the extract_data function and print the output\n",
        "  return module.extract_data()"
      ],
      "metadata": {
        "id": "prjUcK7VXGll"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_features_year(data,year):\n",
        "    feature_map = {\n",
        "        'urbanization': 0,\n",
        "        'avg birth age': 1,\n",
        "        'happiness index': 2,\n",
        "        'health expenditure': 3,\n",
        "        'physicians per capita': 4,\n",
        "        'GNI PPP': 5,\n",
        "        'female labor participation': 6,\n",
        "        'christians (%)': 7,\n",
        "        'muslims (%)': 8,\n",
        "        'no religion (%)': 9,\n",
        "        'buddhists (%)': 10,\n",
        "        'hindus (%)': 11,\n",
        "        'jews (%)': 12,\n",
        "        'other religion (%)': 13,\n",
        "        'in Asia-Pacific':14,\n",
        "        'in Europe':15,\n",
        "        'in Latin America-Caribbean':16,\n",
        "        'in Middle East-North Africa':17,\n",
        "        'in North America':18,\n",
        "        'in Sub-Saharan Africa':19,\n",
        "        'post-HS education men (%)': 20,\n",
        "        'post-HS education women (%)': 21,\n",
        "        'human development index': 22,\n",
        "        'gender inequality index': 23,\n",
        "        'first marriage age women': 24,\n",
        "        'first marriage age men': 25,\n",
        "        'maternity leave index': 26,\n",
        "        'work hours men': 27,\n",
        "        'work hours women': 28,\n",
        "        'abortion rate': 29,\n",
        "        'social media users': 30\n",
        "    }\n",
        "    countries_with_data = sorted(list(set([key[0] for key in data.keys() if key[1] == year])))\n",
        "    index = pd.MultiIndex.from_product([countries_with_data, [year]], names=['country', 'year'])\n",
        "    df = pd.DataFrame(index=index, columns=feature_map.keys())\n",
        "    target=[]\n",
        "    # Populate the DataFrame\n",
        "    for (country, yr) in index:\n",
        "        key = (country, yr)\n",
        "        features = data[key][1]\n",
        "        target.append(data[key][0])\n",
        "        for feature_name, feature_index in feature_map.items():\n",
        "            if feature_index < len(features):\n",
        "              df.loc[key, feature_name] = features[feature_index]\n",
        "              if str(features[feature_index]) =='nan':\n",
        "                df.loc[key, feature_name]=handle_missing_values(data,feature_index,country,year)\n",
        "    return df,target\n",
        "\n",
        "\n",
        "\n",
        "def handle_missing_values(data, feature_index, country, year):\n",
        "    # try taking the value from the last 2 years\n",
        "    for i in range(1, 3):\n",
        "        past_year = year - i\n",
        "        if (country, past_year) in data:\n",
        "            past_data = data[(country, past_year)][1] # Access the list of features\n",
        "            if feature_index < len(past_data) and str(past_data[feature_index])!='nan':\n",
        "                return past_data[feature_index]\n",
        "\n",
        "    # otherwise if missing last 2 years, linearly extrapulate from last 6 years\n",
        "    recent_years_data = []\n",
        "    for i in range(6,0,-1):\n",
        "        past_year = year - i\n",
        "        if (country, past_year) in data:\n",
        "            past_data = data[(country, past_year)][1] # Access the list of features\n",
        "            if feature_index < len(past_data) and not pd.isna(past_data[feature_index]):\n",
        "                 recent_years_data.append((past_year, past_data[feature_index]))\n",
        "\n",
        "    if len(recent_years_data) >= 2:\n",
        "        years = [item[0] for item in recent_years_data]\n",
        "        values = [item[1] for item in recent_years_data]\n",
        "        last_value = values[-1]\n",
        "        # Linear extrapolation using linear regression with polyfit\n",
        "        try:\n",
        "            m, c = np.polyfit(years, values, 1)\n",
        "            extrapolated_value = m * year + c\n",
        "\n",
        "            # Check if extrapolated value is within 50% of last value\n",
        "            if last_value != 0 and abs(extrapolated_value - last_value) / abs(last_value) > 0.3:\n",
        "                return last_value\n",
        "            elif last_value == 0 and abs(extrapolated_value) > 0.3 * np.mean(values): # Handle edge case where last_value is 0\n",
        "                 return last_value\n",
        "            else:\n",
        "                return extrapolated_value\n",
        "        except np.linalg.LinAlgError:\n",
        "            # Handle cases where polyfit fails (e.g., all years are the same)\n",
        "            return last_value # Return the last known value\n",
        "    elif len(recent_years_data) == 1:\n",
        "         # If only one data point in the last 10 years, use that value\n",
        "         return recent_years_data[0][1]\n",
        "\n",
        "    # If still missing after checking last 10 years, return NaN\n",
        "    return np.nan"
      ],
      "metadata": {
        "id": "cCWbIjgpEHDt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_missing_features(df_features):\n",
        "\n",
        "  # Identify countries with and without NaN values\n",
        "  countries_with_nan = df_features[df_features.isnull().any(axis=1)].index.tolist()\n",
        "  countries_without_nan = df_features.dropna().index.tolist()\n",
        "  countries_with_one_nan = df_features[df_features.isnull().sum(axis=1) == 1].index.tolist()\n",
        "\n",
        "  # Print the results\n",
        "  print(\"Countries with NaN values in their features:\")\n",
        "  print(countries_with_nan)\n",
        "  print(\"\\nCountries without NaN values in their features:\")\n",
        "  print(countries_without_nan)\n",
        "  print(\"\\nCountries with exactly one NaN value in their features:\")\n",
        "  print(countries_with_one_nan)\n",
        "\n",
        "  print(f\"\\nNumber of countries with NaN values: {len(countries_with_nan)}\")\n",
        "  print(f\"Number of countries without NaN values: {len(countries_without_nan)}\")\n",
        "  print(f\"Number of countries with exactly one NaN value: {len(countries_with_one_nan)}\")\n",
        "\n",
        "  # Group countries by their single missing feature\n",
        "  missing_features_grouped = {}\n",
        "  if countries_with_one_nan:\n",
        "      for country in countries_with_one_nan:\n",
        "          missing_feature_name = df_features.loc[country].isnull().idxmax()\n",
        "          if missing_feature_name not in missing_features_grouped:\n",
        "              missing_features_grouped[missing_feature_name] = []\n",
        "          missing_features_grouped[missing_feature_name].append(str(country))\n",
        "\n",
        "      # Print countries grouped by missing feature\n",
        "      print(\"\\nMissing feature for countries with exactly one NaN:\")\n",
        "      for feature, countries in missing_features_grouped.items():\n",
        "          print(f\"  Missing feature is '{feature}':\")\n",
        "          print(f\"    Countries: {', '.join(countries)}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4H0S2X3MyK0n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "process all the data:\n",
        "add some missing data, split to train and test and normalize"
      ],
      "metadata": {
        "id": "AHHje3EPAzwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_2023_data(data_output):\n",
        "    df_features, target = calc_features_year(data_output, 2023)\n",
        "    missing_values_to_fill = {\n",
        "        'abortion rate': {\n",
        "            'Cyprus': 7,'Ireland': 6.7,'Malaysia': 11,\n",
        "            'Mauritania': 42,'Malta': 3,'Morocco': 25, 'Congo, Rep.': 39\n",
        "        },\n",
        "        'maternity leave index': {\n",
        "            'Albania': 23.23,'Bosnia and Herzegovina': 52.14,\n",
        "            'Kazakhstan': 18,'Georgia': 7.59,'Kyrgyz Republic': 18,\n",
        "            'Moldova': 18,'Angola': 13,'Armenia': 20,\n",
        "            'Azerbaijan': 18,'Malawi': 12.86,'Bhutan': 8,\n",
        "            'Tanzania': 12,'Tajikistan': 20,'North Macedonia': 39,\n",
        "            'Liberia': 12.86,'Suriname': 0,'Uzbekistan': 18\n",
        "        },\n",
        "        'gender inequality index':{\n",
        "            'Central African Republic':0.682\n",
        "        },\n",
        "        'physicians per capita':{\n",
        "            'Somalia': 0.048, 'Viet Nam': 1.25\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Fill in missing values using the dictionary\n",
        "    for feature, country_values in missing_values_to_fill.items():\n",
        "        for country, value in country_values.items():\n",
        "            if (country,2023) in df_features.index:\n",
        "                df_features.loc[(country,2023), feature] = value\n",
        "\n",
        "    # Convert all columns to numeric, coercing errors\n",
        "    df_features = df_features.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # Create a DataFrame for the target variable\n",
        "    y = pd.Series(target, index=df_features.index, name='target')\n",
        "\n",
        "    # Combine features and target into a single DataFrame for easier NaN handling\n",
        "    combined_df = pd.concat([df_features, y], axis=1)\n",
        "\n",
        "    # Remove rows with NaN values\n",
        "    combined_df_cleaned = combined_df.dropna()\n",
        "\n",
        "    # Separate features and target again\n",
        "    X = combined_df_cleaned.drop('target', axis=1)\n",
        "    y = combined_df_cleaned['target']\n",
        "\n",
        "    return X,y\n",
        "\n",
        "def process_multi_year_data(data_output):\n",
        "  years = [2023, 2007, 1991]\n",
        "  all_features = []\n",
        "  all_targets = []\n",
        "\n",
        "  for year in years:\n",
        "      df_features, target = calc_features_year(data_output, year)\n",
        "      df_features['year'] = year\n",
        "      all_features.append(df_features)\n",
        "      all_targets.extend(target)\n",
        "\n",
        "  X = pd.concat(all_features)\n",
        "  y = pd.Series(all_targets, index=X.index, name='target')\n",
        "\n",
        "  columns_to_drop = [\n",
        "      'christians (%)', 'muslims (%)', 'no religion (%)', 'buddhists (%)',\n",
        "      'hindus (%)', 'jews (%)', 'other religion (%)', 'gender inequality index',\n",
        "      'happiness index', 'first marriage age women', 'first marriage age men',\n",
        "      'work hours men', 'work hours women', 'social media users', 'abortion rate',\n",
        "      'health expenditure' ,'maternity leave index'\n",
        "  ]\n",
        "\n",
        "  X = X.drop(columns=columns_to_drop)\n",
        "  X = X.apply(pd.to_numeric, errors='coerce')\n",
        "  # Add specific missing data points (structured by feature)\n",
        "  missing_values_to_fill_manual = {\n",
        "      'GNI PPP': {\n",
        "          ('Venezuela, RB', 2023): 20017,\n",
        "          ('Syrian Arab Republic', 2007): 3914.3,\n",
        "          ('Nigeria', 2007): 3260.8,\n",
        "          ('Afghanistan', 1991): 1070\n",
        "      },\n",
        "      'female labor participation': {\n",
        "          ('Grenada', 2023): 51.42\n",
        "      },\n",
        "      'physicians per capita': {\n",
        "          ('Hong Kong SAR, China', 2023): 2.1,\n",
        "          ('Hong Kong SAR, China', 2007): 1.13,\n",
        "          ('India', 2007): 0.61\n",
        "      },\n",
        "      'urbanization': {\n",
        "          ('West Bank and Gaza', 2023): 77.58,\n",
        "          ('West Bank and Gaza', 2007): 73.49,\n",
        "          ('Montenegro', 2023): 68.5,\n",
        "          ('Montenegro', 2007): 63.14,\n",
        "          ('Maldives', 2023): 42.41,\n",
        "          ('Maldives', 2007): 35.2,\n",
        "          ('Serbia', 2023): 57.11,\n",
        "          ('Serbia', 2007): 54.33\n",
        "      },\n",
        "      'human development index': {\n",
        "          ('Sudan', 2007): 0.526,\n",
        "          ('Rwanda', 1991): 0.213,\n",
        "          ('Sao Tome and Principe', 1991): 0.399,\n",
        "          ('Ethiopia', 1991): 0.166\n",
        "      }\n",
        "  }\n",
        "\n",
        "  for feature, country_year_values in missing_values_to_fill_manual.items():\n",
        "      if feature in X.columns:\n",
        "          for (country, year), value in country_year_values.items():\n",
        "              if (country, year) in X.index:\n",
        "                  X.loc[(country, year), feature] = value\n",
        "  combined_df = pd.concat([X, y], axis=1)\n",
        "  combined_df_cleaned = combined_df.dropna()\n",
        "\n",
        "  # Separate features and target again\n",
        "  X = combined_df_cleaned.drop('target', axis=1)\n",
        "  y = combined_df_cleaned['target']\n",
        "\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "o11f5CwCA_bK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_features(X_train):\n",
        "\n",
        "  # Get the list of columns\n",
        "  columns = X_train.columns\n",
        "\n",
        "  # Calculate the number of rows needed\n",
        "  n_cols = 5\n",
        "  n_rows = math.ceil(len(columns) / n_cols)\n",
        "\n",
        "  # Create subplots\n",
        "  fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5))\n",
        "  axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
        "\n",
        "  # Plot histograms for all features\n",
        "  for i, column in enumerate(columns):\n",
        "      axes[i].hist(X_train[column], bins=10)\n",
        "      axes[i].set_title(f'Histogram of {column}')\n",
        "      axes[i].set_xlabel(column)\n",
        "      axes[i].set_ylabel('Frequency')\n",
        "      axes[i].grid(True)\n",
        "\n",
        "  # Hide any unused subplots\n",
        "  for j in range(i + 1, len(axes)):\n",
        "      fig.delaxes(axes[j])\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-3EC63LtmKt7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipeline classes to prepare data"
      ],
      "metadata": {
        "id": "rxlOCxQ0bjHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Scaling2023(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self,log_features=None,features_to_scale=None,health_features=None):\n",
        "        self.log_features=log_features or ['no religion (%)','other religion (%)','buddhists (%)','hindus (%)','jews (%)','GNI PPP']\n",
        "        self.health_features=health_features or ['physicians per capita','health expenditure']\n",
        "        self.features_to_scale=features_to_scale or [\n",
        "            'urbanization','avg birth age','happiness index','GNI PPP','female labor participation','christians (%)','muslims (%)','no religion (%)',\n",
        "            'buddhists (%)','hindus (%)','jews (%)','other religion (%)','post-HS education men (%)','post-HS education women (%)',\n",
        "            'human development index','gender inequality index','first marriage age women','first marriage age men','maternity leave index',\n",
        "            'work hours men','work hours women','abortion rate','social media users','healthcare index'\n",
        "        ]\n",
        "        self.health_scaler=StandardScaler()\n",
        "        self.scaler=StandardScaler()\n",
        "\n",
        "    def fit(self,X,y=None):\n",
        "        X_copy=X.copy()\n",
        "        missing=[c for c in (self.health_features+self.log_features) if c not in X_copy.columns]\n",
        "        if missing: raise KeyError(f\"Missing columns: {missing}\")\n",
        "\n",
        "        self.health_scaler.fit(X_copy[self.health_features])\n",
        "        h_scaled=self.health_scaler.transform(X_copy[self.health_features])\n",
        "        score=h_scaled[:,0]+h_scaled[:,1]\n",
        "        X_copy=X_copy.drop(columns=self.health_features)\n",
        "        X_copy['healthcare index']=score\n",
        "        for f in self.log_features:\n",
        "            X_copy[f]=pd.to_numeric(X_copy[f])\n",
        "            X_copy[f]=np.log1p(X_copy[f])\n",
        "        self.scaler.fit(X_copy[self.features_to_scale])\n",
        "        return self\n",
        "\n",
        "    def transform(self,X):\n",
        "        X_copy=X.copy()\n",
        "        h_scaled=self.health_scaler.transform(X_copy[self.health_features])\n",
        "        score=h_scaled[:,0]+h_scaled[:,1]\n",
        "        X_copy=X_copy.drop(columns=self.health_features)\n",
        "        X_copy['healthcare index']=score\n",
        "        for f in self.log_features:\n",
        "            X_copy[f]=pd.to_numeric(X_copy[f])\n",
        "            X_copy[f]=np.log1p(X_copy[f])\n",
        "        X_copy[self.features_to_scale]=self.scaler.transform(X_copy[self.features_to_scale])\n",
        "        return X_copy\n",
        "\n",
        "class ScalingMultiYear(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self,log_features=None,features_to_scale=None):\n",
        "        self.log_features=log_features or ['GNI PPP','physicians per capita']\n",
        "        self.features_to_scale=features_to_scale or [\n",
        "            'urbanization','avg birth age','GNI PPP',\n",
        "            'female labor participation','post-HS education men (%)',\n",
        "            'post-HS education women (%)','human development index',\n",
        "            'physicians per capita'\n",
        "        ]\n",
        "        self.scaler=StandardScaler()\n",
        "\n",
        "    def fit(self,X,y=None):\n",
        "        X_copy=X.copy()\n",
        "        self.scaler.fit(X_copy[self.features_to_scale])\n",
        "        return self\n",
        "\n",
        "    def transform(self,X):\n",
        "        X_copy=X.copy()\n",
        "        for f in self.log_features:\n",
        "            X_copy[f]=pd.to_numeric(X_copy[f])\n",
        "            X_copy[f]=np.log1p(X_copy[f])\n",
        "        X_copy[self.features_to_scale]=self.scaler.transform(X_copy[self.features_to_scale])\n",
        "        return X_copy"
      ],
      "metadata": {
        "id": "fpk0R4uO_ChR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_health_index_score(X_train,X_test):\n",
        "    scaler_healthcare = StandardScaler()\n",
        "    health_features = ['physicians per capita','health expenditure']\n",
        "    X_train[health_features] = scaler_healthcare.fit_transform(X_train[health_features])\n",
        "    X_test[health_features] = scaler_healthcare.transform(X_test[health_features])\n",
        "    X_train['healthcare index'] = X_train['physicians per capita'] + X_train['health expenditure']\n",
        "    X_test['healthcare index'] = X_test['physicians per capita'] + X_test['health expenditure']\n",
        "    X_train = X_train.drop(['physicians per capita', 'health expenditure'], axis=1)\n",
        "    X_test = X_test.drop(['physicians per capita', 'health expenditure'], axis=1)\n",
        "    return X_train,X_test"
      ],
      "metadata": {
        "id": "IvTYKSwz_aR9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_correlations(df, method):\n",
        "    \"\"\"Calculates and visualizes correlation matrix, and prints top 5 correlated pairs.\"\"\"\n",
        "\n",
        "    correlation_matrix = df.corr(method=method)\n",
        "\n",
        "    plt.figure(figsize=(18, 15))\n",
        "    sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title(f'{method.capitalize()} Correlation Heatmap of Features in train set')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nTop 5 most highly correlated pairs of features (absolute {method.capitalize()} correlation):\")\n",
        "    upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
        "    stacked_corr = upper_tri.stack().sort_values(ascending=False, key=abs)\n",
        "    top_5_correlated_pairs = stacked_corr.head(5)\n",
        "\n",
        "    for (feature1, feature2), correlation in top_5_correlated_pairs.items():\n",
        "        print(f\"  {feature1} and {feature2}: {correlation:.4f}\")\n"
      ],
      "metadata": {
        "id": "hOqocTAfnYe2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_target_correlation(X, y, method_name, alpha_threshold=0.001):\n",
        "    combined_data = pd.concat([X, y], axis=1)\n",
        "    correlation_series = combined_data.corr(method=method_name)['target'].drop('target').sort_values(ascending=False)\n",
        "\n",
        "    p_values = {}\n",
        "    correlations = {}\n",
        "\n",
        "    for feature in correlation_series.index:\n",
        "        if method_name == 'pearson':\n",
        "            corr, p_value = stats.pearsonr(combined_data[feature], combined_data['target'])\n",
        "        elif method_name == 'spearman':\n",
        "            corr, p_value = stats.spearmanr(combined_data[feature], combined_data['target'])\n",
        "\n",
        "        correlations[feature] = corr\n",
        "        p_values[feature] = p_value\n",
        "\n",
        "    correlation_series = pd.Series(correlations).loc[correlation_series.index]\n",
        "    p_value_series = pd.Series(p_values).loc[correlation_series.index]\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x=correlation_series.values, y=correlation_series.index, palette='coolwarm')\n",
        "    plt.title(f'{method_name} Correlation of Features with fertility rate')\n",
        "    plt.xlabel(f'{method_name} Correlation Coefficient')\n",
        "    plt.ylabel('Features')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n{method_name} Correlation with fertility rate (with p-values and alpha={alpha_threshold}):\")\n",
        "    for feature, corr in correlation_series.items():\n",
        "        p_value = p_value_series.loc[feature]\n",
        "        p_value_str = \"p<.001\" if p_value < alpha_threshold else f\"p={p_value:.3f}\"\n",
        "        print(f\"  {feature}: {corr:.4f} ({p_value_str})\")\n",
        "    return correlation_series"
      ],
      "metadata": {
        "id": "rP_0P9DHkpAd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_mutual_information(X, y):\n",
        "    \"\"\"Calculates and displays Mutual Information scores of features with the target.\"\"\"\n",
        "    mi_scores = mutual_info_regression(X, y)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "\n",
        "    print(\"Mutual Information Scores of Features with fertility rate:\")\n",
        "    print(mi_scores)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=mi_scores.values, y=mi_scores.index, palette='viridis')\n",
        "    plt.title('Mutual Information Scores of Features with fertility rate')\n",
        "    plt.xlabel('Mutual Information Score')\n",
        "    plt.ylabel('Features')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return mi_scores"
      ],
      "metadata": {
        "id": "iCz9f_EgB21d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gridsearch_loocv_lasso(X,y,scaler):\n",
        "    pipe=Pipeline([('scaler',scaler),('lasso',Lasso(fit_intercept=True))])\n",
        "    param_grid={'lasso__alpha':[val*(10**i) for i in range(-3,3) for val in [1,3]]}\n",
        "    gs=GridSearchCV(pipe,param_grid,cv=LeaveOneOut(),scoring='neg_mean_squared_error',n_jobs=-1)\n",
        "    gs.fit(X,y)\n",
        "    return gs\n",
        "\n",
        "def gridsearch_ridge_loocv(X,y,scaler):\n",
        "    pipe=Pipeline([('scaler',scaler),('ridge',Ridge(fit_intercept=True))])\n",
        "    param_grid={\n",
        "        'ridge__alpha':[val*(10**i) for i in range(-3,3) for val in [1,3]]\n",
        "    }\n",
        "    gs=GridSearchCV(pipe,param_grid,cv=LeaveOneOut(),scoring='neg_mean_squared_error',n_jobs=-1)\n",
        "    gs.fit(X,y)\n",
        "    return gs\n",
        "\n",
        "def gridsearch_random_forest(X,y,scaler):\n",
        "  pipe=Pipeline([('scaler',scaler),('rf',RandomForestRegressor(random_state=42,n_jobs=-1))])\n",
        "  kf=KFold(n_splits=5,shuffle=True,random_state=42)\n",
        "  param_grid = {\n",
        "        'rf__n_estimators': [10, 25, 100, 400],\n",
        "        'rf__max_depth': [2, 4 , 6, None],\n",
        "        'rf__min_samples_split': [2, 3 , 5, 9],\n",
        "        'rf__min_samples_leaf': [1, 2, 4, 6],\n",
        "        'rf__max_features': ['sqrt', 0.5, 1.0],\n",
        "    }\n",
        "  gs=GridSearchCV(pipe,param_grid,cv=kf,scoring='neg_mean_squared_error',n_jobs=-1)\n",
        "  gs.fit(X,y)\n",
        "  return gs\n",
        "\n",
        "\n",
        "def gridsearch_xgboost(X, y,scaler):\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', scaler),\n",
        "        ('xgb', XGBRegressor(tree_method='hist',random_state=42,n_jobs=-1,importance_type='gain'))])\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    param_grid = {\n",
        "        'xgb__n_estimators': [10, 25, 100, 400],\n",
        "        'xgb__learning_rate': [0.001, 0.01 , 0.1,0.5],\n",
        "        'xgb__max_depth': [1, 2, 4],\n",
        "        'xgb__min_child_weight': [1, 10],\n",
        "        'xgb__subsample': [0.7],#decrease overfit\n",
        "        'xgb__colsample_bytree': [0.7],#decrease overfit\n",
        "        'xgb__gamma': [0, 1],\n",
        "        'xgb__reg_alpha': [0, 1],\n",
        "        'xgb__reg_lambda': [1,10],\n",
        "\n",
        "    }\n",
        "    gs=GridSearchCV(pipe,param_grid,cv=kf,scoring='neg_mean_squared_error',n_jobs=-1)\n",
        "    gs.fit(X,y)\n",
        "    return gs\n",
        "\n",
        "def report_grid_search(gs,X,y,model,scaler):\n",
        "  best_est = gs.best_estimator_\n",
        "  names = best_est.named_steps['scaler'].transform(X).columns\n",
        "  idx = gs.best_index_\n",
        "  cv_mse = -gs.cv_results_['mean_test_score'][idx]\n",
        "  print(f\"Best params: {gs.best_params_}\")\n",
        "  print(f\"CV MSE: {cv_mse:.4f} (Â±{gs.cv_results_['std_test_score'][idx]:.4f})\")\n",
        "  print(\"Train accuracy:\")\n",
        "  accuracy_report(best_est,X,y)\n",
        "  est = best_est.named_steps[model]\n",
        "\n",
        "  if model in ['lasso','ridge']:\n",
        "    coefs = pd.Series(est.coef_, index=names)\n",
        "    coefs = coefs.reindex(coefs.abs().sort_values(ascending=False).index)\n",
        "    print(\"\\ncoefficients:\")\n",
        "    for f,c in coefs.items():\n",
        "      print(f\"{f}: {c:.4f}\")\n",
        "  else:#random forest or xgboost\n",
        "    if model=='rf':\n",
        "      print(\"\\nmean decrease in imputirty by feature:\")\n",
        "    if model=='xgb':\n",
        "      print(\"\\nmean gain by feature:\")\n",
        "    imp = pd.Series(est.feature_importances_, index=names).sort_values(ascending=False)\n",
        "    for f,v in imp.items():\n",
        "      print(f\"{f}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "9MNlG-ewC4zC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gridsearch_all_models(X_train,y_train,scaler):\n",
        "  print('\\nlasso regressor:')\n",
        "  lasso_gs = gridsearch_loocv_lasso(X_train,y_train, scaler)\n",
        "  report_grid_search(lasso_gs,X_train,y_train,'lasso', scaler)\n",
        "  print('\\nridge regressor:')\n",
        "  ridge_gs = gridsearch_ridge_loocv(X_train,y_train, scaler)\n",
        "  report_grid_search(ridge_gs,X_train,y_train,'ridge', scaler)\n",
        "  print('\\nrandom forest regressor:')\n",
        "  rf_gs = gridsearch_random_forest(X_train,y_train, scaler)\n",
        "  report_grid_search(rf_gs,X_train,y_train,'rf', scaler)\n",
        "  print('\\nxgboost regressor:')\n",
        "  xgb_gs = gridsearch_xgboost(X_train,y_train, scaler)\n",
        "  report_grid_search(xgb_gs,X_train,y_train,'xgb', scaler)\n",
        "  return lasso_gs, ridge_gs, rf_gs, xgb_gs\n",
        "\n",
        "\n",
        "def accuracy_report(estimator,X,y):\n",
        "  y_pred=estimator.predict(X)\n",
        "  mse=mean_squared_error(y,y_pred)\n",
        "  print(f\"MSE: {mse:.4f}\")\n",
        "\n",
        "def compare_predictions(estimator, X, y):\n",
        "  y_pred = estimator.predict(X)\n",
        "  comparison_df = pd.DataFrame({'Actual': y, 'Predicted': y_pred}, index=X.index)\n",
        "  for index, row in comparison_df.iterrows():\n",
        "      print(f\"For: {index}, Actual: {row['Actual']:.4f}, Predicted: {row['Predicted']:.4f}\")"
      ],
      "metadata": {
        "id": "Brn9Btug4O0y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exec_experiments(data,isMultiYear):\n",
        "  if isMultiYear:\n",
        "    X,y = process_multi_year_data(data)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    unscaled_X_train=X_train.copy()\n",
        "    unscaled_X_test=X_test.copy()\n",
        "    scaler = ScalingMultiYear()\n",
        "    full_data_scaler=ScalingMultiYear()\n",
        "  else:#is only 2023\n",
        "    X,y = process_2023_data(data)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    unscaled_X_train,unscaled_X_test = create_health_index_score(X_train.copy(),X_test.copy())\n",
        "    scaler = Scaling2023()\n",
        "    full_data_scaler=Scaling2023()\n",
        "\n",
        "  print('unscaled features')\n",
        "  plot_features(unscaled_X_train)\n",
        "  scaler.fit(X_train)\n",
        "  scaled_train = scaler.transform(X_train)\n",
        "  scaled_test = scaler.transform(X_test)\n",
        "  print('scaled and transformed features')\n",
        "  plot_features(scaled_train)\n",
        "\n",
        "  #feature pairs correlations\n",
        "  full_data_scaler.fit(X)\n",
        "  scaled_full_data = full_data_scaler.transform(X)\n",
        "  print('\\nfeature pairs correlations:')\n",
        "  feature_correlations(scaled_train, 'pearson')\n",
        "  feature_correlations(scaled_train, 'spearman')\n",
        "  #feature-target correlations and mutual information\n",
        "  Pearson_corr=analyze_target_correlation(scaled_full_data, y, 'pearson')\n",
        "  Spearman_corr=analyze_target_correlation(scaled_full_data, y, 'spearman')\n",
        "  MI_scores=analyze_mutual_information(scaled_full_data, y)\n",
        "  #run grid search of cv on all models\n",
        "  lasso_gs, ridge_gs, rf_gs, xgb_gs = gridsearch_all_models(X_train,y_train, scaler)\n",
        "\n",
        "  # Calculate and print test MSE for each model,\n",
        "  print(\"testing trained models signal strength using test set:\")\n",
        "  print('\\nlasso regressor final results:')\n",
        "  accuracy_report(lasso_gs.best_estimator_,X_test,y_test)\n",
        "  print('\\nridge regressor final results:')\n",
        "  accuracy_report(ridge_gs.best_estimator_,X_test,y_test)\n",
        "  print('\\nrandom forest regressor final results:')\n",
        "  accuracy_report(rf_gs.best_estimator_,X_test,y_test)\n",
        "  print('\\nxgboost regressor final results:')\n",
        "  accuracy_report(xgb_gs.best_estimator_,X_test,y_test)\n",
        "\n",
        "  #plot feature importance comparison\n",
        "  plot_feature_importance_comparison(Pearson_corr, Spearman_corr, MI_scores, lasso_gs, ridge_gs, rf_gs, xgb_gs, X_train)\n",
        "  return X_train, X_test, y_train, y_test, lasso_gs, ridge_gs, rf_gs, xgb_gs"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8lHd4iGFxsFn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf487114"
      },
      "source": [
        "\n",
        "def plot_feature_importance_comparison(Pearson_corr, Spearman_corr, MI_scores, lasso_gs, ridge_gs, rf_gs, xgb_gs, X_train):\n",
        "    \"\"\"\n",
        "    Plots a comparison of various feature importance metrics.\n",
        "    \"\"\"\n",
        "    # Collect data\n",
        "    scaler = lasso_gs.best_estimator_.named_steps['scaler'] # Get scaler from one pipeline\n",
        "    feature_names = scaler.transform(X_train).columns\n",
        "\n",
        "    lasso_coefs = pd.Series(lasso_gs.best_estimator_.named_steps['lasso'].coef_, index=feature_names)\n",
        "    ridge_coefs = pd.Series(ridge_gs.best_estimator_.named_steps['ridge'].coef_, index=feature_names)\n",
        "    rf_importances = pd.Series(rf_gs.best_estimator_.named_steps['rf'].feature_importances_, index=feature_names)\n",
        "    xgb_importances = pd.Series(xgb_gs.best_estimator_.named_steps['xgb'].feature_importances_, index=feature_names)\n",
        "\n",
        "    # Consolidate data\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Pearson Corr': Pearson_corr, 'Spearman Corr': Spearman_corr, 'Mutual Info': MI_scores,\n",
        "        'Lasso Coef': lasso_coefs, 'Ridge Coef': ridge_coefs,\n",
        "        'RF MDI': rf_importances, 'XGB Gain': xgb_importances\n",
        "    }).fillna(0)\n",
        "\n",
        "    # Normalize data\n",
        "    scaler = MinMaxScaler()\n",
        "    importance_df_abs_scaled = pd.DataFrame(scaler.fit_transform(importance_df.abs()), columns=importance_df.columns, index=importance_df.index)\n",
        "\n",
        "    # Structure data for plotting\n",
        "    importance_melted = importance_df_abs_scaled.reset_index().melt(id_vars='index', var_name='Metric', value_name='Scaled Importance (Absolute)').rename(columns={'index': 'Feature'})\n",
        "\n",
        "    # Create visualization\n",
        "    n_features = len(feature_names)\n",
        "    n_cols = 5\n",
        "    n_rows = (n_features + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4), squeeze=False)\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, feature in enumerate(feature_names):\n",
        "        sns.barplot(x='Metric', y='Scaled Importance (Absolute)', hue='Metric', data=importance_melted[importance_melted['Feature'] == feature], ax=axes[i], palette='viridis', legend=False)\n",
        "        axes[i].set_title(feature); axes[i].set_xlabel(''); axes[i].set_ylabel('Scaled Importance'); axes[i].tick_params(axis='x', rotation=45); axes[i].set_ylim(0, 1)\n",
        "\n",
        "\n",
        "    for j in range(i + 1, len(axes)): fig.delaxes(axes[j])\n",
        "    plt.tight_layout(); plt.suptitle('Comparison of Feature Importance Metrics (Scaled Absolute Values)', y=1.02, fontsize=16); plt.show()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_subgroups(isMultiYear=False):\n",
        "  data = {\n",
        "      'Feature/Target': [\n",
        "          'target',\n",
        "          'urbanization',\n",
        "          'avg birth age',\n",
        "          'happiness index',\n",
        "          'health expenditure',\n",
        "          'physicians per capita',\n",
        "          'GNI PPP',\n",
        "          'female labor participation',\n",
        "          'christians (%)',\n",
        "          'muslims (%)',\n",
        "          'no religion (%)',\n",
        "          'buddhists (%)',\n",
        "          'hindus (%)',\n",
        "          'jews (%)',\n",
        "          'other religion (%)',\n",
        "          'in Asia-Pacific',\n",
        "          'in Europe',\n",
        "          'in Latin America-Caribbean',\n",
        "          'in Middle East-North Africa',\n",
        "          'in North America',\n",
        "          'in Sub-Saharan Africa',\n",
        "          'post-HS education men (%)',\n",
        "          'post-HS education women (%)',\n",
        "          'human development index',\n",
        "          'gender inequality index',\n",
        "          'first marriage age women',\n",
        "          'first marriage age men',\n",
        "          'maternity leave index',\n",
        "          'work hours men',\n",
        "          'work hours women',\n",
        "          'abortion rate',\n",
        "          'social media users'\n",
        "      ],\n",
        "      'Haredim': [\n",
        "          6.4, 91.53, 31.3, 7.341, 4008, 3.713, 29213, 81, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 1, 0, 0, 4.2, 14, 0.847, 0.525, 22, 23, 14, 36.5, 32.5, 8.1, 0.32\n",
        "      ],\n",
        "      'Non Haredim jews': [\n",
        "          2.5, 74.26, 31.3, 7.341, 4008, 3.713, 51498, 83, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 1, 0, 0, 31.3, 45.1, 0.959, 0.043, 28, 30, 14, 45, 38.5, 8.1, 0.911\n",
        "      ],\n",
        "      'Arabs': [\n",
        "          2.75, 42.5, 27.7, 7.341, 4008, 3.713, 29420, 33.7, 7.7, 83.3, 0, 0, 0, 0, 9, 0, 0, 0, 1, 0, 0, 10.8, 23.3, 0.856, 0.237, 23.11, 26.96, 14, 43.4, 36.5, 5.99, 0.7128\n",
        "      ]\n",
        "  }\n",
        "\n",
        "  # Create DataFrame\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "  # Transpose the DataFrame so that the first column becomes the index and the other columns become rows\n",
        "  df_transposed = df.set_index('Feature/Target').T\n",
        "\n",
        "  # Separate the target variable as a Series\n",
        "  target_series = df_transposed['target']\n",
        "  features_df = df_transposed.drop(columns=['target'])\n",
        "\n",
        "  if isMultiYear:\n",
        "      multi_year_features = [\n",
        "          'urbanization',\n",
        "          'avg birth age',\n",
        "          'physicians per capita',\n",
        "          'GNI PPP',\n",
        "          'female labor participation',\n",
        "          'in Asia-Pacific',\n",
        "          'in Europe',\n",
        "          'in Latin America-Caribbean',\n",
        "          'in Middle East-North Africa',\n",
        "          'in North America',\n",
        "          'in Sub-Saharan Africa',\n",
        "          'post-HS education men (%)',\n",
        "          'post-HS education women (%)',\n",
        "          'human development index',\n",
        "      ]\n",
        "      features_df = features_df[multi_year_features].copy()\n",
        "      features_df['year'] = 2023\n",
        "\n",
        "  return features_df, target_series"
      ],
      "metadata": {
        "id": "6JO18OYm3Qlt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_subgroups(data,isMultiYear):\n",
        "  if isMultiYear:\n",
        "    X_train,y_train = process_multi_year_data(data)\n",
        "    scaler=ScalingMultiYear()\n",
        "  else:\n",
        "    X_train,y_train = process_2023_data(data)\n",
        "    scaler=Scaling2023()\n",
        "  X_test,y_test= prep_subgroups(isMultiYear)\n",
        "  if ('Israel', 2023) in X_train.index:\n",
        "    israel_X_2023 = X_train.loc[('Israel', 2023)].to_frame().T\n",
        "    israel_y_2023 = pd.Series(y_train.loc[('Israel', 2023)], index=israel_X_2023.index, name=y_train.name)\n",
        "    X_test = pd.concat([X_test, israel_X_2023])\n",
        "    y_test = pd.concat([y_test, israel_y_2023])\n",
        "    X_train = X_train.drop(('Israel', 2023))\n",
        "    y_train = y_train.drop(('Israel', 2023))\n",
        "\n",
        "\n",
        "  lasso_gs, ridge_gs, rf_gs, xgb_gs = gridsearch_all_models(X_train,y_train, scaler)\n",
        "\n",
        "  print(\"testing model accuracy on sub groups\")\n",
        "  print('\\nlasso regressor results for subgroups:')\n",
        "  compare_predictions(lasso_gs.best_estimator_,X_test,y_test)\n",
        "  print('\\nridge regressor final results:')\n",
        "  compare_predictions(ridge_gs.best_estimator_,X_test,y_test)\n",
        "  print('\\nrandom forest regressor final results:')\n",
        "  compare_predictions(rf_gs.best_estimator_,X_test,y_test)\n",
        "  print('\\nxgboost regressor final results:')\n",
        "  compare_predictions(xgb_gs.best_estimator_,X_test,y_test)"
      ],
      "metadata": {
        "id": "d5WP9cf6Wv5t"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_causal_effects(df, outcome):\n",
        "    X_causal = df.copy()\n",
        "    features_to_log = [\n",
        "      'christians (%)','muslims (%)','no religion (%)','buddhists (%)',\n",
        "      'hindus (%)','jews (%)','other religion (%)','GNI PPP'\n",
        "    ]\n",
        "\n",
        "    for feature in features_to_log:\n",
        "        if feature in X_causal.columns:\n",
        "            X_causal[feature] = pd.to_numeric(X_causal[feature])\n",
        "            X_causal[feature] = np.log1p(X_causal[feature])\n",
        "    print(\"\\ntesting causal effect of social media usage\")\n",
        "    analyze_causal_effect(X_causal, outcome, 'social media users')\n",
        "\n",
        "def analyze_causal_effect(df, outcome, treatment):\n",
        "    controls = [c for c in ('urbanization','GNI PPP','first marriage age women','avg birth age','maternity leave index',\n",
        "          'muslims (%)','jews (%)','no religion (%)','buddhists (%)','hindus (%)','other religion (%)',\n",
        "          'in Asia-Pacific','in Europe','in Latin America-Caribbean','in Middle East-North Africa','in North America') if c in df.columns]\n",
        "    data = pd.concat([df[[treatment]+controls], outcome], axis=1).apply(pd.to_numeric, errors='coerce')\n",
        "    #supressing internal dowhy warning spam\n",
        "    logging.getLogger(\"dowhy\").setLevel(logging.ERROR)\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", message=\"Series.__getitem__ treating keys as positions is deprecated\")\n",
        "        warnings.filterwarnings(\"ignore\", category=FutureWarning, module=r\".*dowhy.*\")\n",
        "\n",
        "        model = CausalModel(data=data, treatment=treatment, outcome=outcome.name, common_causes=controls)\n",
        "        ie = model.identify_effect()\n",
        "        est = model.estimate_effect(ie, method_name=\"backdoor.linear_regression\")\n",
        "\n",
        "        X = sm.add_constant(data[[treatment]+controls]); Y = data[outcome.name]\n",
        "        ols = sm.OLS(Y, X).fit(); l, h = ols.conf_int().loc[treatment]\n",
        "        print(f\"coef={ols.params[treatment]:.4f}, CI=[{l:.4f},{h:.4f}], Change in fertility caused by a 10% increase in social media usage={0.1*ols.params[treatment]:.4f}\")\n",
        "\n",
        "        #run robustness checks\n",
        "        print(\"\\nRunning robustness checks:\")\n",
        "\n",
        "        # Placebo Treatment Refuter\n",
        "        placebo = model.refute_estimate(ie, est, method_name=\"placebo_treatment_refuter\", random_state=42)\n",
        "        print(f\"Placebo Test: {placebo.refutation_result}\")\n",
        "\n",
        "        # Data Subset Refuter\n",
        "        subset = model.refute_estimate(ie, est, method_name=\"data_subset_refuter\",\n",
        "                                       subset_fraction=0.8, num_simulations=100, random_state=42)\n",
        "        print(f\"Data Subset Test: {subset.refutation_result}\")\n",
        "\n",
        "        # Random Common Cause Refuter\n",
        "        random_cause = model.refute_estimate(ie, est, method_name=\"random_common_cause\", random_state=42)\n",
        "        print(f\"Random Common Cause Test: {random_cause.refutation_result}\")\n",
        "\n",
        "        # Unobserved Confounder Refuter\n",
        "        # This refuter doesn't have a simple True/False refute_result.\n",
        "        # It provides a sensitivity analysis result.\n",
        "        unobserved = model.refute_estimate(ie, est, method_name=\"add_unobserved_common_cause\", random_state=42)\n",
        "        print(f\"Unobserved Confounder Test (Sensitivity Analysis): {unobserved.refutation_result}\")"
      ],
      "metadata": {
        "id": "PORJ52t52nRb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=init_process()\n",
        "\"\"\"\n",
        "print(\"2023 data analysis\")\n",
        "X_train_2023, X_test_2023, y_train_2023, y_test_2023, lasso_gs_2023, ridge_gs_2023, rf_gs_2023, xgb_gs_2023 = exec_experiments(data,False)\n",
        "print(\"multiple year(1991,2007,2023) data analysis\")\n",
        "X_train_multi, X_test_multi, y_train_multi, y_test_multi, lasso_gs_multi, ridge_gs_multi, rf_gs_multi, xgb_gs_multi = exec_experiments(data,True)\n",
        "\"\"\"\n",
        "print(\"testing the success of models for 2023 country fertility rate on subgroups\")\n",
        "test_subgroups(data,False)\n",
        "print(\"testing the success of models for multi year country fertility rate on subgroups\")\n",
        "test_subgroups(data,True)\n",
        "X,y=process_2023_data(data)\n",
        "test_causal_effects(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y6r-hNMk6_9n",
        "outputId": "ad0e4611-5a93-431b-8c88-73c8123c4d8f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded extract_data.py to data_extraction_code/extract_data.py\n",
            "Downloaded GNI_PPP_const_2021_dollars.csv to data/GNI_PPP_const_2021_dollars.csv\n",
            "Downloaded Religious-Composition-percentages.csv to data/Religious-Composition-percentages.csv\n",
            "Downloaded abortion-rates-by-country-2025.csv to data/abortion-rates-by-country-2025.csv\n",
            "Downloaded age-at-first-marriage-by-country-2025.csv to data/age-at-first-marriage-by-country-2025.csv\n",
            "Downloaded average-workweek-by-country-2025.csv to data/average-workweek-by-country-2025.csv\n",
            "Downloaded female-labor-force-participation-rates-slopes.csv to data/female-labor-force-participation-rates-slopes.csv\n",
            "Downloaded female-labor-participation.csv to data/female-labor-participation.csv\n",
            "Downloaded gender-inequality-index.xlsx to data/gender-inequality-index.xlsx\n",
            "Downloaded happiness-cantril-ladder.csv to data/happiness-cantril-ladder.csv\n",
            "Downloaded healthcare-expenditure-per-capita-ppp.csv to data/healthcare-expenditure-per-capita-ppp.csv\n",
            "Downloaded high_education_female.xlsx to data/high_education_female.xlsx\n",
            "Downloaded high_education_male.xlsx to data/high_education_male.xlsx\n",
            "Downloaded human_development_index.xlsx to data/human_development_index.xlsx\n",
            "Downloaded maternity-leave-by-country-2025.csv to data/maternity-leave-by-country-2025.csv\n",
            "Downloaded period-average-age-of-mothers.csv to data/period-average-age-of-mothers.csv\n",
            "Downloaded physicians-per-capita.csv to data/physicians-per-capita.csv\n",
            "Downloaded social-media-users-by-country-2025.csv to data/social-media-users-by-country-2025.csv\n",
            "Downloaded total-fertility-rate.csv to data/total-fertility-rate.csv\n",
            "Downloaded urban-population-share.csv to data/urban-population-share.csv\n",
            "testing the success of models for 2023 country fertility rate on subgroups\n",
            "\n",
            "lasso regressor:\n",
            "Best params: {'lasso__alpha': 0.003}\n",
            "CV MSE: 0.2053 (Â±0.3651)\n",
            "Train accuracy:\n",
            "MSE: 0.1329\n",
            "\n",
            "coefficients:\n",
            "human development index: -0.8155\n",
            "in Sub-Saharan Africa: 0.7421\n",
            "social media users: -0.4255\n",
            "in Middle East-North Africa: 0.3864\n",
            "gender inequality index: 0.2894\n",
            "healthcare index: 0.2838\n",
            "happiness index: 0.2024\n",
            "post-HS education men (%): 0.1676\n",
            "first marriage age women: -0.1561\n",
            "avg birth age: 0.1421\n",
            "muslims (%): 0.1115\n",
            "urbanization: 0.1061\n",
            "work hours men: -0.0783\n",
            "abortion rate: 0.0694\n",
            "other religion (%): -0.0458\n",
            "female labor participation: 0.0428\n",
            "hindus (%): -0.0387\n",
            "no religion (%): 0.0264\n",
            "christians (%): -0.0260\n",
            "jews (%): -0.0234\n",
            "work hours women: -0.0202\n",
            "in Europe: -0.0154\n",
            "maternity leave index: 0.0006\n",
            "in Asia-Pacific: 0.0000\n",
            "GNI PPP: 0.0000\n",
            "buddhists (%): -0.0000\n",
            "post-HS education women (%): -0.0000\n",
            "in North America: -0.0000\n",
            "in Latin America-Caribbean: -0.0000\n",
            "first marriage age men: -0.0000\n",
            "\n",
            "ridge regressor:\n",
            "Best params: {'ridge__alpha': 3}\n",
            "CV MSE: 0.2095 (Â±0.3834)\n",
            "Train accuracy:\n",
            "MSE: 0.1393\n",
            "\n",
            "coefficients:\n",
            "human development index: -0.5418\n",
            "social media users: -0.4469\n",
            "in Sub-Saharan Africa: 0.4354\n",
            "gender inequality index: 0.3332\n",
            "healthcare index: 0.2229\n",
            "in Latin America-Caribbean: -0.2033\n",
            "happiness index: 0.1795\n",
            "avg birth age: 0.1560\n",
            "in Asia-Pacific: -0.1477\n",
            "in Europe: -0.1403\n",
            "post-HS education men (%): 0.1364\n",
            "muslims (%): 0.1218\n",
            "GNI PPP: -0.1202\n",
            "in Middle East-North Africa: 0.1047\n",
            "urbanization: 0.0946\n",
            "first marriage age women: -0.0924\n",
            "work hours men: -0.0730\n",
            "first marriage age men: -0.0684\n",
            "female labor participation: 0.0622\n",
            "abortion rate: 0.0613\n",
            "post-HS education women (%): -0.0528\n",
            "in North America: -0.0488\n",
            "hindus (%): -0.0472\n",
            "no religion (%): 0.0425\n",
            "other religion (%): -0.0390\n",
            "christians (%): -0.0279\n",
            "jews (%): -0.0278\n",
            "work hours women: -0.0238\n",
            "buddhists (%): -0.0200\n",
            "maternity leave index: 0.0038\n",
            "\n",
            "random forest regressor:\n",
            "Best params: {'rf__max_depth': None, 'rf__max_features': 0.5, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2, 'rf__n_estimators': 25}\n",
            "CV MSE: 0.2060 (Â±0.1264)\n",
            "Train accuracy:\n",
            "MSE: 0.0599\n",
            "\n",
            "mean decrease in imputirty by feature:\n",
            "social media users: 0.5327\n",
            "in Sub-Saharan Africa: 0.1212\n",
            "human development index: 0.0800\n",
            "healthcare index: 0.0770\n",
            "GNI PPP: 0.0721\n",
            "gender inequality index: 0.0282\n",
            "post-HS education women (%): 0.0157\n",
            "first marriage age women: 0.0089\n",
            "post-HS education men (%): 0.0074\n",
            "maternity leave index: 0.0065\n",
            "female labor participation: 0.0053\n",
            "hindus (%): 0.0049\n",
            "work hours women: 0.0048\n",
            "first marriage age men: 0.0044\n",
            "abortion rate: 0.0040\n",
            "muslims (%): 0.0039\n",
            "christians (%): 0.0038\n",
            "avg birth age: 0.0036\n",
            "happiness index: 0.0036\n",
            "buddhists (%): 0.0033\n",
            "urbanization: 0.0020\n",
            "other religion (%): 0.0018\n",
            "work hours men: 0.0017\n",
            "no religion (%): 0.0015\n",
            "jews (%): 0.0012\n",
            "in Middle East-North Africa: 0.0002\n",
            "in Europe: 0.0001\n",
            "in Asia-Pacific: 0.0001\n",
            "in Latin America-Caribbean: 0.0000\n",
            "in North America: 0.0000\n",
            "\n",
            "xgboost regressor:\n",
            "Best params: {'xgb__colsample_bytree': 0.7, 'xgb__gamma': 0, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 2, 'xgb__min_child_weight': 1, 'xgb__n_estimators': 100, 'xgb__reg_alpha': 0, 'xgb__reg_lambda': 1, 'xgb__subsample': 0.7}\n",
            "CV MSE: 0.2148 (Â±0.0985)\n",
            "Train accuracy:\n",
            "MSE: 0.0245\n",
            "\n",
            "mean gain by feature:\n",
            "in Sub-Saharan Africa: 0.5407\n",
            "social media users: 0.1710\n",
            "healthcare index: 0.0885\n",
            "human development index: 0.0490\n",
            "GNI PPP: 0.0267\n",
            "gender inequality index: 0.0256\n",
            "first marriage age women: 0.0134\n",
            "muslims (%): 0.0130\n",
            "jews (%): 0.0067\n",
            "hindus (%): 0.0061\n",
            "no religion (%): 0.0058\n",
            "post-HS education women (%): 0.0055\n",
            "avg birth age: 0.0052\n",
            "post-HS education men (%): 0.0050\n",
            "first marriage age men: 0.0049\n",
            "female labor participation: 0.0042\n",
            "happiness index: 0.0040\n",
            "christians (%): 0.0036\n",
            "work hours women: 0.0035\n",
            "urbanization: 0.0033\n",
            "work hours men: 0.0033\n",
            "abortion rate: 0.0031\n",
            "buddhists (%): 0.0026\n",
            "in Asia-Pacific: 0.0021\n",
            "maternity leave index: 0.0016\n",
            "other religion (%): 0.0015\n",
            "in Europe: 0.0000\n",
            "in Middle East-North Africa: 0.0000\n",
            "in North America: 0.0000\n",
            "in Latin America-Caribbean: 0.0000\n",
            "testing model accuracy on sub groups\n",
            "\n",
            "lasso regressor results for subgroups:\n",
            "For: Haredim, Actual: 6.4000, Predicted: 2.8007\n",
            "For: Non Haredim jews, Actual: 2.5000, Predicted: 0.3011\n",
            "For: Arabs, Actual: 2.7500, Predicted: 1.7716\n",
            "For: ('Israel', 2023), Actual: 2.8500, Predicted: 1.0784\n",
            "\n",
            "ridge regressor final results:\n",
            "For: Haredim, Actual: 6.4000, Predicted: 2.7821\n",
            "For: Non Haredim jews, Actual: 2.5000, Predicted: 0.1882\n",
            "For: Arabs, Actual: 2.7500, Predicted: 1.7427\n",
            "For: ('Israel', 2023), Actual: 2.8500, Predicted: 0.8318\n",
            "\n",
            "random forest regressor final results:\n",
            "For: Haredim, Actual: 6.4000, Predicted: 1.9021\n",
            "For: Non Haredim jews, Actual: 2.5000, Predicted: 1.2011\n",
            "For: Arabs, Actual: 2.7500, Predicted: 1.8498\n",
            "For: ('Israel', 2023), Actual: 2.8500, Predicted: 1.4054\n",
            "\n",
            "xgboost regressor final results:\n",
            "For: Haredim, Actual: 6.4000, Predicted: 2.0698\n",
            "For: Non Haredim jews, Actual: 2.5000, Predicted: 1.3464\n",
            "For: Arabs, Actual: 2.7500, Predicted: 1.8398\n",
            "For: ('Israel', 2023), Actual: 2.8500, Predicted: 1.4116\n",
            "testing the success of models for multi year country fertility rate on subgroups\n",
            "\n",
            "lasso regressor:\n",
            "Best params: {'lasso__alpha': 0.003}\n",
            "CV MSE: 0.3890 (Â±0.6615)\n",
            "Train accuracy:\n",
            "MSE: 0.3671\n",
            "\n",
            "coefficients:\n",
            "human development index: -1.4061\n",
            "in Europe: -0.4347\n",
            "in Sub-Saharan Africa: 0.4181\n",
            "avg birth age: 0.3762\n",
            "in Asia-Pacific: -0.3518\n",
            "post-HS education men (%): 0.1308\n",
            "post-HS education women (%): 0.0822\n",
            "female labor participation: -0.0287\n",
            "year: -0.0179\n",
            "urbanization: 0.0169\n",
            "physicians per capita: 0.0000\n",
            "GNI PPP: 0.0000\n",
            "in North America: 0.0000\n",
            "in Latin America-Caribbean: -0.0000\n",
            "in Middle East-North Africa: 0.0000\n",
            "\n",
            "ridge regressor:\n",
            "Best params: {'ridge__alpha': 3}\n",
            "CV MSE: 0.3915 (Â±0.6608)\n",
            "Train accuracy:\n",
            "MSE: 0.3671\n",
            "\n",
            "coefficients:\n",
            "human development index: -1.3750\n",
            "in Sub-Saharan Africa: 0.4818\n",
            "in Europe: -0.3965\n",
            "avg birth age: 0.3714\n",
            "in Asia-Pacific: -0.3107\n",
            "in North America: 0.1364\n",
            "post-HS education men (%): 0.1230\n",
            "post-HS education women (%): 0.0801\n",
            "in Middle East-North Africa: 0.0580\n",
            "female labor participation: -0.0312\n",
            "in Latin America-Caribbean: 0.0310\n",
            "year: -0.0182\n",
            "physicians per capita: -0.0152\n",
            "urbanization: 0.0107\n",
            "GNI PPP: -0.0000\n",
            "\n",
            "random forest regressor:\n",
            "Best params: {'rf__max_depth': None, 'rf__max_features': 0.5, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 400}\n",
            "CV MSE: 0.3584 (Â±0.0399)\n",
            "Train accuracy:\n",
            "MSE: 0.0478\n",
            "\n",
            "mean decrease in imputirty by feature:\n",
            "human development index: 0.4293\n",
            "GNI PPP: 0.1702\n",
            "physicians per capita: 0.1290\n",
            "post-HS education women (%): 0.1022\n",
            "avg birth age: 0.0472\n",
            "post-HS education men (%): 0.0283\n",
            "in Sub-Saharan Africa: 0.0246\n",
            "female labor participation: 0.0230\n",
            "urbanization: 0.0175\n",
            "year: 0.0091\n",
            "in Asia-Pacific: 0.0070\n",
            "in Europe: 0.0063\n",
            "in Middle East-North Africa: 0.0051\n",
            "in Latin America-Caribbean: 0.0013\n",
            "in North America: 0.0000\n",
            "\n",
            "xgboost regressor:\n",
            "Best params: {'xgb__colsample_bytree': 0.7, 'xgb__gamma': 0, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 4, 'xgb__min_child_weight': 10, 'xgb__n_estimators': 100, 'xgb__reg_alpha': 1, 'xgb__reg_lambda': 1, 'xgb__subsample': 0.7}\n",
            "CV MSE: 0.3428 (Â±0.0524)\n",
            "Train accuracy:\n",
            "MSE: 0.0942\n",
            "\n",
            "mean gain by feature:\n",
            "human development index: 0.3014\n",
            "GNI PPP: 0.1784\n",
            "physicians per capita: 0.1115\n",
            "in Sub-Saharan Africa: 0.0920\n",
            "post-HS education women (%): 0.0770\n",
            "in Middle East-North Africa: 0.0728\n",
            "in Asia-Pacific: 0.0622\n",
            "avg birth age: 0.0325\n",
            "in Europe: 0.0197\n",
            "year: 0.0157\n",
            "female labor participation: 0.0132\n",
            "urbanization: 0.0115\n",
            "post-HS education men (%): 0.0074\n",
            "in Latin America-Caribbean: 0.0048\n",
            "in North America: 0.0000\n",
            "testing model accuracy on sub groups\n",
            "\n",
            "lasso regressor results for subgroups:\n",
            "For: Haredim, Actual: 6.4000, Predicted: 1.7174\n",
            "For: Non Haredim jews, Actual: 2.5000, Predicted: 0.9923\n",
            "For: Arabs, Actual: 2.7500, Predicted: 0.8896\n",
            "For: ('Israel', 2023), Actual: 2.8500, Predicted: 1.6493\n",
            "\n",
            "ridge regressor final results:\n",
            "For: Haredim, Actual: 6.4000, Predicted: 1.7404\n",
            "For: Non Haredim jews, Actual: 2.5000, Predicted: 1.0304\n",
            "For: Arabs, Actual: 2.7500, Predicted: 0.9439\n",
            "For: ('Israel', 2023), Actual: 2.8500, Predicted: 1.6692\n",
            "\n",
            "random forest regressor final results:\n",
            "For: Haredim, Actual: 6.4000, Predicted: 2.2936\n",
            "For: Non Haredim jews, Actual: 2.5000, Predicted: 1.9173\n",
            "For: Arabs, Actual: 2.7500, Predicted: 2.3749\n",
            "For: ('Israel', 2023), Actual: 2.8500, Predicted: 1.8900\n",
            "\n",
            "xgboost regressor final results:\n",
            "For: Haredim, Actual: 6.4000, Predicted: 2.3145\n",
            "For: Non Haredim jews, Actual: 2.5000, Predicted: 1.9200\n",
            "For: Arabs, Actual: 2.7500, Predicted: 2.1771\n",
            "For: ('Israel', 2023), Actual: 2.8500, Predicted: 1.9344\n",
            "\n",
            "testing causal effect of social media usage\n",
            "coef=-2.8199, CI=[-3.7792,-1.8606], Change in fertility caused by a 10% increase in social media usage=-0.2820\n",
            "Placebo: new_effect=4.884981308350689e-14  note={'p_value': np.float64(0.0), 'is_statistically_significant': np.True_}\n",
            "Subset:  new_effect=-2.8882604409676365  note={'p_value': np.float64(0.0), 'is_statistically_significant': np.True_}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=init_process()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyRQH74PeR2F",
        "outputId": "fa332857-518b-4853-9fac-1c010d3468aa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded extract_data.py to data_extraction_code/extract_data.py\n",
            "Downloaded GNI_PPP_const_2021_dollars.csv to data/GNI_PPP_const_2021_dollars.csv\n",
            "Downloaded Religious-Composition-percentages.csv to data/Religious-Composition-percentages.csv\n",
            "Downloaded abortion-rates-by-country-2025.csv to data/abortion-rates-by-country-2025.csv\n",
            "Downloaded age-at-first-marriage-by-country-2025.csv to data/age-at-first-marriage-by-country-2025.csv\n",
            "Downloaded average-workweek-by-country-2025.csv to data/average-workweek-by-country-2025.csv\n",
            "Downloaded female-labor-force-participation-rates-slopes.csv to data/female-labor-force-participation-rates-slopes.csv\n",
            "Downloaded female-labor-participation.csv to data/female-labor-participation.csv\n",
            "Downloaded gender-inequality-index.xlsx to data/gender-inequality-index.xlsx\n",
            "Downloaded happiness-cantril-ladder.csv to data/happiness-cantril-ladder.csv\n",
            "Downloaded healthcare-expenditure-per-capita-ppp.csv to data/healthcare-expenditure-per-capita-ppp.csv\n",
            "Downloaded high_education_female.xlsx to data/high_education_female.xlsx\n",
            "Downloaded high_education_male.xlsx to data/high_education_male.xlsx\n",
            "Downloaded human_development_index.xlsx to data/human_development_index.xlsx\n",
            "Downloaded maternity-leave-by-country-2025.csv to data/maternity-leave-by-country-2025.csv\n",
            "Downloaded period-average-age-of-mothers.csv to data/period-average-age-of-mothers.csv\n",
            "Downloaded physicians-per-capita.csv to data/physicians-per-capita.csv\n",
            "Downloaded social-media-users-by-country-2025.csv to data/social-media-users-by-country-2025.csv\n",
            "Downloaded total-fertility-rate.csv to data/total-fertility-rate.csv\n",
            "Downloaded urban-population-share.csv to data/urban-population-share.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 2023 data\n",
        "X_2023, y_2023 = process_2023_data(data)\n",
        "\n",
        "# Remove Israel's data from the training set\n",
        "if ('Israel', 2023) in X_2023.index:\n",
        "    X_2023_train = X_2023.drop(('Israel', 2023))\n",
        "    y_2023_train = y_2023.drop(('Israel', 2023))\n",
        "else:\n",
        "    X_2023_train = X_2023\n",
        "    y_2023_train = y_2023\n",
        "\n",
        "\n",
        "# Define scaler for 2023 data\n",
        "scaler_2023 = Scaling2023()\n",
        "\n",
        "# Perform Lasso grid search on the training data\n",
        "lasso_gs_2023 = gridsearch_loocv_lasso(X_2023_train, y_2023_train, scaler_2023)\n",
        "\n",
        "# Get the best Lasso estimator\n",
        "best_lasso_model = lasso_gs_2023.best_estimator_\n",
        "\n",
        "# Extract Israel's data for 2023 from the original full data\n",
        "israel_data_2023 = X_2023.loc[('Israel', 2023)].to_frame().T\n",
        "\n",
        "# Predict fertility rate for Israel in 2023\n",
        "predicted_fertility_israel_2023 = best_lasso_model.predict(israel_data_2023)\n",
        "\n",
        "print(f\"Predicted fertility rate for Israel in 2023 using the best Lasso model: {predicted_fertility_israel_2023[0]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WsIzjkdcAar",
        "outputId": "16f4d457-3d00-415e-e3ff-c9e1e130fe76"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted fertility rate for Israel in 2023 using the best Lasso model: 1.0784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    import dill\n",
        "\n",
        "    filename = 'my_session.pkl'\n",
        "    dill.dump_session(filename)"
      ],
      "metadata": {
        "id": "e_y8oMSi8eWU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    import dill\n",
        "\n",
        "    filename = 'my_session.pkl'\n",
        "    dill.load_session(filename)"
      ],
      "metadata": {
        "id": "FxWrKZMd8q7h"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dill\n",
        "\n",
        "filename = 'my_session (3).pkl'\n",
        "dill.load_session(filename)"
      ],
      "metadata": {
        "id": "jG4WH2d1-GL0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "9fc6b437-d892-45a9-836e-0a8dc65da171"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'my_session (3).pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1264100872.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'my_session (3).pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dill/session.py\u001b[0m in \u001b[0;36mload_session\u001b[0;34m(filename, main, **kwds)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"load_session() has been renamed load_module().\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPendingDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m     \u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0mload_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dill/session.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(filename, module, **kwds)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEMPDIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'session.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_peekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_session (3).pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=init_process()\n",
        "X,y=process_2023_data(data)\n"
      ],
      "metadata": {
        "id": "rpkhLi4qCVwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_df = y.to_frame()\n",
        "plot_features(y_df)"
      ],
      "metadata": {
        "id": "JaXmyQKyC7rB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}